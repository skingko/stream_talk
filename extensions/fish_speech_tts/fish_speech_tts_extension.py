#!/usr/bin/env python3
"""
Fish Speech TTS Extension for TEN Framework
åŸºäºFish Speechå®ç°é«˜æ€§èƒ½å®æ—¶è¯­éŸ³åˆæˆ
"""

import asyncio
import logging
import time
import json
import numpy as np
from pathlib import Path
from typing import Optional, Dict, Any, AsyncGenerator
import torch

from ten import (
    Extension,
    TenEnv,
    Cmd,
    StatusCode,
    CmdResult,
    Data,
)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class FishSpeechTTSExtension(Extension):
    """Fish Speech TTSæ‰©å±•"""
    
    def __init__(self, name: str):
        super().__init__(name)
        self.tts_engine = None
        self.model_path = None
        self.device = None
        self.is_initialized = False
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            'total_requests': 0,
            'total_processing_time': 0.0,
            'average_rtf': 0.0
        }
    
    def on_configure(self, ten_env: TenEnv) -> None:
        """é…ç½®æ‰©å±•"""
        logger.info("ğŸŸ é…ç½®Fish Speech TTSæ‰©å±•")
        
        # ä»é…ç½®ä¸­è·å–å‚æ•°
        self.model_path = ten_env.get_property_string("model_path") or "models/fish-speech/openaudio-s1-mini"
        self.device = ten_env.get_property_string("device") or "auto"
        
        # è®¾ç½®è®¾å¤‡
        if self.device == "auto":
            if torch.cuda.is_available():
                self.device = "cuda"
            elif torch.backends.mps.is_available():
                self.device = "mps"
            else:
                self.device = "cpu"
        
        logger.info(f"ğŸ“ æ¨¡å‹è·¯å¾„: {self.model_path}")
        logger.info(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        ten_env.on_configure_done()
    
    def on_init(self, ten_env: TenEnv) -> None:
        """åˆå§‹åŒ–æ‰©å±•"""
        logger.info("ğŸš€ åˆå§‹åŒ–Fish Speech TTSæ‰©å±•")
        
        try:
            # å¼‚æ­¥åˆå§‹åŒ–æ¨¡å‹
            asyncio.create_task(self._init_fish_speech_model())
            ten_env.on_init_done()
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            ten_env.on_init_done()
    
    async def _init_fish_speech_model(self):
        """å¼‚æ­¥åˆå§‹åŒ–Fish Speechæ¨¡å‹"""
        try:
            logger.info("ğŸ“¦ å¼€å§‹åŠ è½½Fish Speechæ¨¡å‹...")
            start_time = time.time()
            
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
            model_path = Path(self.model_path)
            if not model_path.exists():
                logger.error(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
                return
            
            # å°è¯•åŠ è½½å®˜æ–¹Fish Speech API
            try:
                from fish_speech_tts_engine import FishSpeechEngine
                self.tts_engine = FishSpeechEngine(
                    model_path=str(model_path),
                    device=self.device
                )
                await self.tts_engine.initialize()
                
            except ImportError:
                logger.warning("âš ï¸ å®˜æ–¹Fish Speech APIä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå¼•æ“")
                from fish_speech_simulator import FishSpeechSimulator
                self.tts_engine = FishSpeechSimulator(
                    model_path=str(model_path),
                    device=self.device
                )
                await self.tts_engine.initialize()
            
            load_time = time.time() - start_time
            self.is_initialized = True
            
            logger.info(f"âœ… Fish Speechæ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.2f}s")
            logger.info(f"ğŸ¯ é¢„æœŸRTF: < 1.0 (å®æ—¶æ€§èƒ½)")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.is_initialized = False
    
    def on_start(self, ten_env: TenEnv) -> None:
        """å¯åŠ¨æ‰©å±•"""
        logger.info("â–¶ï¸ å¯åŠ¨Fish Speech TTSæ‰©å±•")
        ten_env.on_start_done()
    
    def on_stop(self, ten_env: TenEnv) -> None:
        """åœæ­¢æ‰©å±•"""
        logger.info("â¹ï¸ åœæ­¢Fish Speech TTSæ‰©å±•")
        
        # æ¸…ç†èµ„æº
        if self.tts_engine:
            try:
                self.tts_engine.cleanup()
            except:
                pass
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        if self.stats['total_requests'] > 0:
            logger.info("ğŸ“Š Fish Speech TTSç»Ÿè®¡:")
            logger.info(f"   æ€»è¯·æ±‚æ•°: {self.stats['total_requests']}")
            logger.info(f"   å¹³å‡RTF: {self.stats['average_rtf']:.3f}")
            logger.info(f"   æ€»å¤„ç†æ—¶é—´: {self.stats['total_processing_time']:.2f}s")
        
        ten_env.on_stop_done()
    
    def on_deinit(self, ten_env: TenEnv) -> None:
        """ååˆå§‹åŒ–æ‰©å±•"""
        logger.info("ğŸ”š ååˆå§‹åŒ–Fish Speech TTSæ‰©å±•")
        ten_env.on_deinit_done()
    
    def on_cmd(self, ten_env: TenEnv, cmd: Cmd) -> None:
        """å¤„ç†å‘½ä»¤"""
        cmd_name = cmd.get_name()
        
        if cmd_name == "tts":
            self._handle_tts_command(ten_env, cmd)
        elif cmd_name == "get_stats":
            self._handle_get_stats_command(ten_env, cmd)
        else:
            logger.warning(f"âš ï¸ æœªçŸ¥å‘½ä»¤: {cmd_name}")
            cmd_result = CmdResult.create(StatusCode.ERROR)
            cmd_result.set_property_string("detail", f"Unknown command: {cmd_name}")
            ten_env.return_result(cmd_result, cmd)
    
    def _handle_tts_command(self, ten_env: TenEnv, cmd: Cmd) -> None:
        """å¤„ç†TTSå‘½ä»¤"""
        try:
            # æ£€æŸ¥åˆå§‹åŒ–çŠ¶æ€
            if not self.is_initialized:
                logger.error("âŒ Fish Speechæ¨¡å‹æœªåˆå§‹åŒ–")
                cmd_result = CmdResult.create(StatusCode.ERROR)
                cmd_result.set_property_string("detail", "Model not initialized")
                ten_env.return_result(cmd_result, cmd)
                return
            
            # è·å–æ–‡æœ¬
            text = cmd.get_property_string("text")
            if not text:
                logger.error("âŒ ç¼ºå°‘æ–‡æœ¬å‚æ•°")
                cmd_result = CmdResult.create(StatusCode.ERROR)
                cmd_result.set_property_string("detail", "Missing text parameter")
                ten_env.return_result(cmd_result, cmd)
                return
            
            # è·å–å¯é€‰å‚æ•°
            emotion = cmd.get_property_string("emotion") or "neutral"
            streaming = cmd.get_property_bool("streaming") or False
            
            logger.info(f"ğŸµ å¼€å§‹åˆæˆ: {text[:50]}...")
            
            # å¼‚æ­¥å¤„ç†TTS
            asyncio.create_task(self._process_tts_async(ten_env, cmd, text, emotion, streaming))
            
        except Exception as e:
            logger.error(f"âŒ TTSå‘½ä»¤å¤„ç†å¤±è´¥: {e}")
            cmd_result = CmdResult.create(StatusCode.ERROR)
            cmd_result.set_property_string("detail", str(e))
            ten_env.return_result(cmd_result, cmd)
    
    async def _process_tts_async(self, ten_env: TenEnv, cmd: Cmd, text: str, emotion: str, streaming: bool) -> None:
        """å¼‚æ­¥å¤„ç†TTSè¯·æ±‚"""
        try:
            start_time = time.time()
            
            if streaming:
                # æµå¼å¤„ç†
                async for audio_chunk in self._synthesize_streaming(text, emotion):
                    # å‘é€éŸ³é¢‘å—
                    data = Data.create("audio_chunk")
                    data.set_property_buf("audio_data", audio_chunk.tobytes())
                    data.set_property_int("sample_rate", 22050)
                    data.set_property_string("format", "pcm_f32le")
                    ten_env.send_data(data)
                
                # å‘é€å®Œæˆä¿¡å·
                end_time = time.time()
                processing_time = end_time - start_time
                
                cmd_result = CmdResult.create(StatusCode.OK)
                cmd_result.set_property_float("processing_time", processing_time)
                cmd_result.set_property_bool("streaming", True)
                ten_env.return_result(cmd_result, cmd)
                
            else:
                # æ‰¹é‡å¤„ç†
                audio_data = await self._synthesize_batch(text, emotion)
                
                end_time = time.time()
                processing_time = end_time - start_time
                
                # è®¡ç®—RTF
                estimated_duration = len(text) * 0.15  # ä¸­æ–‡çº¦æ¯å­—ç¬¦0.15ç§’
                rtf = processing_time / estimated_duration if estimated_duration > 0 else 0
                
                # æ›´æ–°ç»Ÿè®¡
                self._update_stats(processing_time, rtf)
                
                # å‘é€ç»“æœ
                data = Data.create("audio_data")
                data.set_property_buf("audio_data", audio_data.tobytes())
                data.set_property_int("sample_rate", 22050)
                data.set_property_string("format", "pcm_f32le")
                data.set_property_float("duration", estimated_duration)
                ten_env.send_data(data)
                
                cmd_result = CmdResult.create(StatusCode.OK)
                cmd_result.set_property_float("processing_time", processing_time)
                cmd_result.set_property_float("rtf", rtf)
                cmd_result.set_property_bool("streaming", False)
                ten_env.return_result(cmd_result, cmd)
                
                logger.info(f"âœ… åˆæˆå®Œæˆï¼ŒRTF: {rtf:.3f}, å¤„ç†æ—¶é—´: {processing_time:.3f}s")
                
        except Exception as e:
            logger.error(f"âŒ TTSå¤„ç†å¤±è´¥: {e}")
            cmd_result = CmdResult.create(StatusCode.ERROR)
            cmd_result.set_property_string("detail", str(e))
            ten_env.return_result(cmd_result, cmd)
    
    async def _synthesize_streaming(self, text: str, emotion: str) -> AsyncGenerator[np.ndarray, None]:
        """æµå¼è¯­éŸ³åˆæˆ"""
        try:
            async for chunk in self.tts_engine.synthesize_streaming(text, emotion=emotion):
                yield chunk
        except Exception as e:
            logger.error(f"âŒ æµå¼åˆæˆå¤±è´¥: {e}")
            raise
    
    async def _synthesize_batch(self, text: str, emotion: str) -> np.ndarray:
        """æ‰¹é‡è¯­éŸ³åˆæˆ"""
        try:
            audio_data = await self.tts_engine.synthesize(text, emotion=emotion)
            return audio_data
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡åˆæˆå¤±è´¥: {e}")
            raise
    
    def _handle_get_stats_command(self, ten_env: TenEnv, cmd: Cmd) -> None:
        """å¤„ç†è·å–ç»Ÿè®¡ä¿¡æ¯å‘½ä»¤"""
        try:
            cmd_result = CmdResult.create(StatusCode.OK)
            cmd_result.set_property_int("total_requests", self.stats['total_requests'])
            cmd_result.set_property_float("total_processing_time", self.stats['total_processing_time'])
            cmd_result.set_property_float("average_rtf", self.stats['average_rtf'])
            cmd_result.set_property_bool("is_initialized", self.is_initialized)
            ten_env.return_result(cmd_result, cmd)
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            cmd_result = CmdResult.create(StatusCode.ERROR)
            cmd_result.set_property_string("detail", str(e))
            ten_env.return_result(cmd_result, cmd)
    
    def _update_stats(self, processing_time: float, rtf: float) -> None:
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        self.stats['total_requests'] += 1
        self.stats['total_processing_time'] += processing_time
        
        # è®¡ç®—å¹³å‡RTF
        if self.stats['total_requests'] > 0:
            self.stats['average_rtf'] = (
                (self.stats['average_rtf'] * (self.stats['total_requests'] - 1) + rtf) / 
                self.stats['total_requests']
            )

def create_extension(name: str) -> Extension:
    """åˆ›å»ºæ‰©å±•å®ä¾‹"""
    return FishSpeechTTSExtension(name)
