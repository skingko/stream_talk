#!/usr/bin/env python3
"""
ç®€åŒ–çš„å®æ—¶è¯­éŸ³äº¤äº’æœåŠ¡å™¨
ä¸“æ³¨äºè§£å†³WebSocketè¿æ¥ç¨³å®šæ€§é—®é¢˜
"""

import asyncio
import logging
import json
import time
import base64
import numpy as np
import os
import sys
import argparse
from typing import Dict, Any, Optional
from dataclasses import dataclass

# FastAPIå’ŒWebSocket
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import requests

@dataclass
class VADConfig:
    """VADé…ç½®ç±» - å‚è€ƒTEN VADé…ç½®"""
    energy_threshold: float = 0.005  # èƒ½é‡é˜ˆå€¼ï¼Œé™ä½é¿å…è¿‡æ•æ„Ÿ
    peak_threshold: float = 0.02     # å³°å€¼é˜ˆå€¼
    silence_duration_frames: int = 30  # é™éŸ³æŒç»­å¸§æ•° (1.5ç§’)
    min_speech_frames: int = 16       # æœ€å°è¯­éŸ³å¸§æ•° (0.8ç§’)
    min_audio_length: int = 800       # æœ€å°éŸ³é¢‘é•¿åº¦ (50ms)
    prefix_padding_ms: int = 120      # å‰ç¼€å¡«å……æ¯«ç§’æ•°
    hop_size_ms: int = 50            # è·³è·ƒå¤§å°æ¯«ç§’æ•°

@dataclass
class WhisperConfig:
    """Whisperé…ç½®ç±» - ä½¿ç”¨large-v3-turboä¼˜åŒ–ä¸­æ–‡æ”¯æŒ"""
    model_size: str = "large-v3-turbo"  # ä½¿ç”¨large-v3-turboæ¨¡å‹ï¼Œä¸­æ–‡æ”¯æŒæœ€ä½³
    device: str = "cpu"               # è®¾å¤‡
    compute_type: str = "int8"        # è®¡ç®—ç±»å‹
    beam_size: int = 5                # beamæœç´¢å¤§å°ï¼Œlargeæ¨¡å‹å¯ä»¥ç”¨æ›´å¤§çš„beam_size
    temperature: float = 0.0          # æ¸©åº¦å‚æ•°
    compression_ratio_threshold: float = 2.4  # å‹ç¼©æ¯”é˜ˆå€¼
    log_prob_threshold: float = -1.0  # å¯¹æ•°æ¦‚ç‡é˜ˆå€¼
    no_speech_threshold: float = 0.6  # æ— è¯­éŸ³é˜ˆå€¼

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SimpleVoiceServer:
    """ç®€åŒ–çš„è¯­éŸ³äº¤äº’æœåŠ¡å™¨"""

    def __init__(self):
        self.app = FastAPI(title="Simple Voice Interaction Server")
        self.active_connections: Dict[str, WebSocket] = {}
        self.conversation_states: Dict[str, Dict[str, Any]] = {}

        # è¯­éŸ³ç¼“å†²åŒº - ç”¨äºç´¯ç§¯è¯­éŸ³æ•°æ®
        self.speech_buffers: Dict[str, Dict[str, Any]] = {}

        # å›éŸ³æŠ‘åˆ¶ - è®°å½•AIè¯´è¯æ—¶é—´
        self.ai_speaking_periods: Dict[str, Dict[str, float]] = {}  # connection_id -> {"start_time": float, "end_time": float}
        self.echo_suppression_delay = 2.0  # AIè¯´è¯ç»“æŸå2ç§’å†…å¿½ç•¥ç”¨æˆ·è¾“å…¥

        # LLMé…ç½®
        self.lm_studio_url = "http://localhost:1234/v1/chat/completions"

        # Spark-TTSå¼•æ“
        self.spark_tts = None

        # éŸ³é¢‘å—ç¼“å†²å’Œå»é‡
        self.audio_chunk_buffer = {}  # æŒ‰connection_idç¼“å†²éŸ³é¢‘å—
        self.sent_audio_hashes = {}   # è®°å½•å·²å‘é€çš„éŸ³é¢‘å—å“ˆå¸Œï¼Œé˜²æ­¢é‡å¤

        # é…ç½®å®ä¾‹ - å‚è€ƒTENæ¡†æ¶ä¼˜åŒ–
        self.vad_config = VADConfig()
        self.whisper_config = WhisperConfig()

        self._setup_routes()
        self._setup_middleware()

    async def initialize_spark_tts(self):
        """åˆå§‹åŒ–Spark-TTS"""
        try:
            logger.info("âš¡ åˆå§‹åŒ–Spark-TTS...")

            from spark_tts_wrapper import SparkTTSWrapper

            self.spark_tts = SparkTTSWrapper()

            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åŠ è½½æˆåŠŸ
            if self.spark_tts.is_model_loaded():
                logger.info("âœ… Spark-TTSæ¨¡å‹åŠ è½½æˆåŠŸ")
                model_info = self.spark_tts.get_model_info()
                logger.info(f"ğŸ“‹ æ¨¡å‹ä¿¡æ¯: {model_info}")
                return True
            else:
                raise RuntimeError("Spark-TTSæ¨¡å‹æœªå®Œå…¨åŠ è½½")

        except Exception as e:
            logger.error(f"âŒ Spark-TTSåˆå§‹åŒ–å¤±è´¥: {e}")
            raise RuntimeError(f"Spark-TTSåˆå§‹åŒ–å¤±è´¥: {e}")
    
    def _setup_middleware(self):
        """è®¾ç½®ä¸­é—´ä»¶"""
        self.app.add_middleware(
            CORSMiddleware,
            allow_origins=["*"],
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )
    
    def _setup_routes(self):
        """è®¾ç½®è·¯ç”±"""
        
        @self.app.get("/")
        async def root():
            return {
                "message": "Simple Voice Interaction Server",
                "version": "1.0.0",
                "status": "running"
            }
        
        @self.app.get("/health")
        async def health():
            return {
                "status": "healthy",
                "active_connections": len(self.active_connections),
                "conversations": len(self.conversation_states)
            }
        
        @self.app.websocket("/ws/voice")
        async def websocket_endpoint(websocket: WebSocket):
            await self._handle_websocket_connection(websocket)

        @self.app.post("/api/chat")
        async def chat_endpoint(request: dict):
            return await self._handle_chat_request(request)
    
    async def _handle_websocket_connection(self, websocket: WebSocket):
        """å¤„ç†WebSocketè¿æ¥"""
        connection_id = f"conn_{int(time.time() * 1000)}_{id(websocket)}"
        
        try:
            await websocket.accept()
            self.active_connections[connection_id] = websocket
            logger.info(f"ğŸ”Œ WebSocketè¿æ¥å»ºç«‹: {connection_id}")
            
            # å‘é€è¿æ¥ç¡®è®¤
            await self._send_to_connection(connection_id, {
                "type": "connection_established",
                "data": {
                    "connection_id": connection_id,
                    "server_time": time.time()
                }
            })
            
            # æ¶ˆæ¯å¤„ç†å¾ªç¯ - å®ç°å¥å£®çš„å¾ªç¯ç›‘å¬é€»è¾‘
            while connection_id in self.active_connections:
                try:
                    message = await websocket.receive_text()
                    await self._process_websocket_message(connection_id, message)
                except WebSocketDisconnect:
                    logger.info(f"ğŸ”Œ WebSocketæ­£å¸¸æ–­å¼€: {connection_id}")
                    break
                except Exception as e:
                    logger.warning(f"âš ï¸ æ¶ˆæ¯å¤„ç†å¼‚å¸¸: {e}, ç»§ç»­ç›‘å¬...")
                    # å‘ç”Ÿå¼‚å¸¸æ—¶ï¼Œç¡®ä¿ç³»ç»Ÿèƒ½æ¢å¤åˆ°ç›‘å¬çŠ¶æ€
                    await self._ensure_listening_state(connection_id)
                    # çŸ­æš‚å»¶è¿Ÿåç»§ç»­ç›‘å¬
                    await asyncio.sleep(1)
        
        except Exception as e:
            logger.error(f"âŒ WebSocketè¿æ¥é”™è¯¯: {e}")
        
        finally:
            # æ¸…ç†è¿æ¥
            await self._cleanup_connection(connection_id)
    
    async def _process_websocket_message(self, connection_id: str, message: str):
        """å¤„ç†WebSocketæ¶ˆæ¯"""
        try:
            data = json.loads(message)
            message_type = data.get("type")
            
            logger.debug(f"ğŸ“¨ æ”¶åˆ°æ¶ˆæ¯: {message_type} from {connection_id}")
            
            if message_type == "ping":
                # å¿ƒè·³å“åº”
                await self._send_to_connection(connection_id, {
                    "type": "pong",
                    "data": {"timestamp": time.time()}
                })
            
            elif message_type == "start_conversation":
                # å¼€å§‹å¯¹è¯
                conversation_id = data.get("data", {}).get("conversation_id", f"conv_{int(time.time() * 1000)}")
                await self._start_conversation(connection_id, conversation_id)
            
            elif message_type == "stop_conversation":
                # åœæ­¢å¯¹è¯
                await self._stop_conversation(connection_id)
            
            elif message_type == "text_message":
                # å¤„ç†æ–‡æœ¬æ¶ˆæ¯
                await self._process_text_message(connection_id, data.get("data", {}))
            
            elif message_type == "init":
                # åˆå§‹åŒ–æ¶ˆæ¯
                logger.info(f"ğŸ”§ æ”¶åˆ°åˆå§‹åŒ–æ¶ˆæ¯: {connection_id}")
                await self._send_to_connection(connection_id, {
                    "type": "init_response",
                    "data": {
                        "status": "ready",
                        "connection_id": connection_id,
                        "timestamp": time.time()
                    }
                })

            elif message_type == "audio_data":
                # å¤„ç†éŸ³é¢‘æ•°æ®
                logger.info(f"ğŸµ å¼€å§‹å¤„ç†éŸ³é¢‘æ•°æ®: {connection_id}")
                await self._process_audio_data(connection_id, data.get("data", {}))

            else:
                logger.warning(f"âš ï¸ æœªçŸ¥æ¶ˆæ¯ç±»å‹: {message_type}")
        
        except Exception as e:
            logger.error(f"âŒ æ¶ˆæ¯å¤„ç†å¤±è´¥: {connection_id}, {e}")
    
    async def _start_conversation(self, connection_id: str, conversation_id: str):
        """å¼€å§‹å¯¹è¯"""
        try:
            self.conversation_states[connection_id] = {
                "conversation_id": conversation_id,
                "started_at": time.time(),
                "message_count": 0
            }
            
            await self._send_to_connection(connection_id, {
                "type": "conversation_started",
                "data": {"conversation_id": conversation_id}
            })
            
            logger.info(f"ğŸ¯ å¯¹è¯å¼€å§‹: {conversation_id}")
        
        except Exception as e:
            logger.error(f"âŒ å¼€å§‹å¯¹è¯å¤±è´¥: {e}")
    
    async def _stop_conversation(self, connection_id: str):
        """åœæ­¢å¯¹è¯"""
        try:
            conversation_state = self.conversation_states.get(connection_id, {})
            conversation_id = conversation_state.get("conversation_id", "unknown")
            
            await self._send_to_connection(connection_id, {
                "type": "conversation_stopped",
                "data": {"conversation_id": conversation_id}
            })
            
            if connection_id in self.conversation_states:
                del self.conversation_states[connection_id]
            
            logger.info(f"ğŸ›‘ å¯¹è¯åœæ­¢: {conversation_id}")
        
        except Exception as e:
            logger.error(f"âŒ åœæ­¢å¯¹è¯å¤±è´¥: {e}")
    
    async def _process_text_message(self, connection_id: str, text_data: Dict[str, Any]):
        """å¤„ç†æ–‡æœ¬æ¶ˆæ¯"""
        try:
            text = text_data.get("text", "")
            if not text:
                return
            
            conversation_state = self.conversation_states.get(connection_id, {})
            conversation_id = conversation_state.get("conversation_id", "unknown")
            
            logger.info(f"ğŸ’¬ æ”¶åˆ°æ–‡æœ¬æ¶ˆæ¯: '{text}' from {conversation_id}")
            
            # å‘é€è½¬å½•ç»“æœç¡®è®¤
            await self._send_to_connection(connection_id, {
                "type": "transcription_result",
                "data": {
                    "text": text,
                    "confidence": 1.0,
                    "conversation_id": conversation_id
                }
            })
            
            # è·å–LLMå“åº”
            response = await self._get_llm_response(text)
            
            # å‘é€LLMå“åº”
            await self._send_to_connection(connection_id, {
                "type": "llm_response",
                "data": {
                    "text": response,
                    "conversation_id": conversation_id
                }
            })
            
            # æ¨¡æ‹ŸTTSäº‹ä»¶
            await self._send_to_connection(connection_id, {
                "type": "tts_start",
                "data": {
                    "text": response,
                    "conversation_id": conversation_id
                }
            })
            
            # çŸ­æš‚å»¶è¿Ÿæ¨¡æ‹ŸTTSæ’­æ”¾
            await asyncio.sleep(1)
            
            await self._send_to_connection(connection_id, {
                "type": "tts_end",
                "data": {
                    "text": response,
                    "conversation_id": conversation_id
                }
            })
            
            # æ›´æ–°æ¶ˆæ¯è®¡æ•°
            if connection_id in self.conversation_states:
                self.conversation_states[connection_id]["message_count"] += 1
        
        except Exception as e:
            logger.error(f"âŒ æ–‡æœ¬å¤„ç†å¤±è´¥: {e}")
    
    async def _get_llm_response(self, text: str) -> str:
        """è·å–LLMå“åº”"""
        try:
            logger.info(f"ğŸ¤– è¯·æ±‚LLMå“åº”: '{text}'")
            
            # æ£€æŸ¥LM Studioæ˜¯å¦å¯ç”¨
            try:
                response = requests.post(
                    self.lm_studio_url,
                    json={
                        "model": "qwen2.5-32b-instruct",
                        "messages": [
                            {"role": "system", "content": """ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ã€‚è¯·ç”¨ç®€æ´ã€è‡ªç„¶çš„ä¸­æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

é‡è¦ï¼šä½ çš„å›ç­”å°†é€šè¿‡è¯­éŸ³åˆæˆæ’­æ”¾ï¼Œè¯·åœ¨å›ç­”ä¸­é€‚å½“ä½¿ç”¨æƒ…æ„Ÿå’Œè¯­è°ƒæ ‡è®°æ¥å¢å¼ºè¡¨è¾¾æ•ˆæœï¼š

åŸºç¡€æƒ…æ„Ÿæ ‡è®°ï¼š
(angry) (sad) (excited) (surprised) (satisfied) (delighted) (scared) (worried) (upset) (nervous) (frustrated) (depressed) (empathetic) (embarrassed) (disgusted) (moved) (proud) (relaxed) (grateful) (confident) (interested) (curious) (confused) (joyful)

é«˜çº§æƒ…æ„Ÿæ ‡è®°ï¼š
(disdainful) (unhappy) (anxious) (hysterical) (indifferent) (impatient) (guilty) (scornful) (panicked) (furious) (reluctant) (keen) (disapproving) (negative) (denying) (astonished) (serious) (sarcastic) (conciliative) (comforting) (sincere) (sneering) (hesitating) (yielding) (painful) (awkward) (amused)

è¯­è°ƒæ ‡è®°ï¼š
(in a hurry tone) (shouting) (screaming) (whispering) (soft tone)

ç‰¹æ®ŠéŸ³æ•ˆï¼š
(laughing) (chuckling) (sobbing) (crying loudly) (sighing) (panting) (groaning) (crowd laughing) (background laughter) (audience laughing)

ä½¿ç”¨ç¤ºä¾‹ï¼š
- è¡¨è¾¾é«˜å…´ï¼š(joyful)å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼
- è¡¨è¾¾å…³å¿ƒï¼š(empathetic)æˆ‘ç†è§£æ‚¨çš„æ„Ÿå—ã€‚
- è¡¨è¾¾è‡ªä¿¡ï¼š(confident)æˆ‘å¯ä»¥å¸®æ‚¨è§£å†³è¿™ä¸ªé—®é¢˜ã€‚
- è¡¨è¾¾æ¸©æŸ”ï¼š(soft tone)è®©æˆ‘æ¥ä¸ºæ‚¨è¯¦ç»†è§£é‡Šä¸€ä¸‹ã€‚

è¯·æ ¹æ®å¯¹è¯å†…å®¹å’Œæƒ…å¢ƒï¼Œè‡ªç„¶åœ°åœ¨å›ç­”ä¸­åŠ å…¥åˆé€‚çš„æƒ…æ„Ÿæ ‡è®°ï¼Œè®©è¯­éŸ³æ›´ç”ŸåŠ¨æœ‰è¶£ã€‚"""},
                            {"role": "user", "content": text}
                        ],
                        "temperature": 0.7,
                        "max_tokens": 1000,  # å¢åŠ tokené™åˆ¶
                        "stream": False
                    },
                    timeout=10
                )
                
                if response.status_code == 200:
                    data = response.json()
                    llm_response = data["choices"][0]["message"]["content"].strip()

                    # è¿‡æ»¤æ‰æ€è€ƒè¿‡ç¨‹ï¼ˆ<think>æ ‡ç­¾å†…å®¹ï¼‰
                    original_response = llm_response
                    if "</think>" in llm_response:
                        # æœ‰å®Œæ•´çš„</think>æ ‡ç­¾ï¼Œå–æ ‡ç­¾åçš„å†…å®¹
                        llm_response = llm_response.split("</think>")[-1].strip()
                    elif "<think>" in llm_response:
                        # å¦‚æœæœ‰<think>ä½†æ²¡æœ‰</think>ï¼Œè¯´æ˜å“åº”è¢«æˆªæ–­
                        # æ£€æŸ¥æ˜¯å¦æœ‰<think>ä¹‹å‰çš„å†…å®¹
                        before_think = llm_response.split("<think>")[0].strip()
                        if before_think:
                            llm_response = before_think
                        else:
                            # å¦‚æœ<think>ä¹‹å‰æ²¡æœ‰å†…å®¹ï¼Œå°è¯•ä»åŸå§‹å“åº”ä¸­æå–æœ‰ç”¨ä¿¡æ¯
                            # æˆ–è€…ä½¿ç”¨é»˜è®¤å›å¤
                            llm_response = "æˆ‘ç†è§£äº†æ‚¨çš„æ„æ€ã€‚"

                    # å¦‚æœè¿‡æ»¤åä¸ºç©ºï¼Œæä¾›é»˜è®¤å›å¤
                    if not llm_response:
                        llm_response = "æˆ‘ç†è§£äº†æ‚¨çš„æ„æ€ã€‚"

                    logger.info(f"âœ… LLMåŸå§‹å“åº”: '{data['choices'][0]['message']['content'][:100]}...'")
                    logger.info(f"âœ… LLMè¿‡æ»¤åå“åº”: '{llm_response}'")
                    return llm_response
                else:
                    logger.error(f"âŒ LLMè¯·æ±‚å¤±è´¥: {response.status_code}")
                    return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜ã€‚"
            
            except requests.exceptions.ConnectionError:
                logger.error("âŒ LM Studioæœªè¿æ¥")
                raise Exception("LM Studioæœªè¿æ¥")

            except requests.exceptions.Timeout:
                logger.error("âŒ LLMè¯·æ±‚è¶…æ—¶")
                raise Exception("LLMè¯·æ±‚è¶…æ—¶")
        
        except Exception as e:
            logger.error(f"âŒ LLMè¯·æ±‚å¼‚å¸¸: {e}")
            raise
    
    async def _send_to_connection(self, connection_id: str, message: Dict[str, Any]) -> bool:
        """å‘é€æ¶ˆæ¯åˆ°è¿æ¥"""
        try:
            websocket = self.active_connections.get(connection_id)
            if websocket:
                await websocket.send_json(message)
                logger.debug(f"ğŸ“¤ æ¶ˆæ¯å·²å‘é€: {message.get('type')} to {connection_id}")
                return True
            else:
                logger.warning(f"âš ï¸ è¿æ¥ä¸å­˜åœ¨: {connection_id}")
                return False
        except Exception as e:
            # æ£€æŸ¥æ˜¯å¦æ˜¯è¿æ¥æ–­å¼€ç›¸å…³çš„é”™è¯¯
            error_msg = str(e).lower()
            if "not connected" in error_msg or "connection closed" in error_msg:
                logger.debug(f"ğŸ”Œ è¿æ¥å·²æ–­å¼€: {connection_id}")
            else:
                logger.error(f"âŒ å‘é€æ¶ˆæ¯å¤±è´¥: {connection_id}, {e}")

            # å½“å‘é€å¤±è´¥æ—¶ï¼Œè¯´æ˜è¿æ¥å·²ç»æ–­å¼€ï¼Œä¸»åŠ¨æ¸…ç†è¿æ¥çŠ¶æ€
            if connection_id in self.active_connections:
                logger.info(f"ğŸ§¹ æ£€æµ‹åˆ°è¿æ¥æ–­å¼€ï¼Œæ¸…ç†è¿æ¥çŠ¶æ€: {connection_id}")
                del self.active_connections[connection_id]
            return False

    def _is_ai_speaking_or_recently_spoke(self, connection_id: str) -> bool:
        """æ£€æŸ¥AIæ˜¯å¦æ­£åœ¨è¯´è¯æˆ–åˆšåˆšè¯´å®Œè¯ï¼ˆå›éŸ³æŠ‘åˆ¶ï¼‰"""
        if connection_id not in self.ai_speaking_periods:
            return False

        speaking_info = self.ai_speaking_periods[connection_id]
        current_time = time.time()

        # å¦‚æœAIæ­£åœ¨è¯´è¯ï¼ˆè¿˜æ²¡æœ‰ç»“æŸæ—¶é—´ï¼‰
        if speaking_info["end_time"] is None:
            return True

        # å¦‚æœAIåˆšè¯´å®Œè¯ï¼Œåœ¨æŠ‘åˆ¶å»¶è¿Ÿæ—¶é—´å†…
        time_since_end = current_time - speaking_info["end_time"]
        if time_since_end < self.echo_suppression_delay:
            return True

        return False

    async def _ensure_listening_state(self, connection_id: str):
        """ç¡®ä¿ç³»ç»Ÿæ¢å¤åˆ°ç›‘å¬çŠ¶æ€"""
        try:
            if connection_id in self.active_connections:
                logger.info(f"ğŸ”„ æ¢å¤ç›‘å¬çŠ¶æ€: {connection_id}")
                await self._send_to_connection(connection_id, {
                    "type": "listening_ready",
                    "data": {
                        "message": "ç³»ç»Ÿå·²æ¢å¤ï¼Œå‡†å¤‡æ¥æ”¶è¯­éŸ³è¾“å…¥",
                        "timestamp": time.time()
                    }
                })
        except Exception as e:
            logger.warning(f"âš ï¸ æ¢å¤ç›‘å¬çŠ¶æ€å¤±è´¥: {e}")

    async def _cleanup_connection(self, connection_id: str):
        """æ¸…ç†è¿æ¥"""
        try:
            # ç§»é™¤è¿æ¥
            if connection_id in self.active_connections:
                del self.active_connections[connection_id]

            # ç§»é™¤å¯¹è¯çŠ¶æ€
            if connection_id in self.conversation_states:
                del self.conversation_states[connection_id]

            # æ¸…ç†éŸ³é¢‘ç›¸å…³æ•°æ®
            if connection_id in self.audio_chunk_buffer:
                del self.audio_chunk_buffer[connection_id]

            if connection_id in self.sent_audio_hashes:
                del self.sent_audio_hashes[connection_id]

            # æ¸…ç†è¯­éŸ³ç¼“å†²åŒº
            conversation_id = f"conv_{connection_id}"
            if conversation_id in self.speech_buffers:
                del self.speech_buffers[conversation_id]

            # æ¸…ç†AIè¯´è¯è®°å½•
            if connection_id in self.ai_speaking_periods:
                del self.ai_speaking_periods[connection_id]

            logger.info(f"ğŸ§¹ è¿æ¥æ¸…ç†å®Œæˆ: {connection_id}")

        except Exception as e:
            logger.error(f"âŒ è¿æ¥æ¸…ç†å¤±è´¥: {e}")

    async def _handle_chat_request(self, request: dict):
        """å¤„ç†æ–‡æœ¬èŠå¤©è¯·æ±‚"""
        try:
            message = request.get("message", "")
            if not message:
                return {"error": "æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©º"}

            # è·å–LLMå“åº”
            response = await self._get_llm_response(message)

            return {
                "response": response,
                "timestamp": time.time()
            }

        except Exception as e:
            logger.error(f"âŒ èŠå¤©è¯·æ±‚å¤„ç†å¤±è´¥: {e}")
            return {"error": str(e)}

    def _reset_speech_buffer(self, conversation_id: str):
        """é‡ç½®è¯­éŸ³ç¼“å†²åŒº"""
        self.speech_buffers[conversation_id] = {
            "buffer": [],
            "last_speech_time": time.time(),
            "silence_count": 0,
            "is_speaking": False,
            "speech_started": False,
            "current_transcript": "",
            "last_transcription_time": 0
        }
        logger.info(f"ğŸ”„ é‡ç½®è¯­éŸ³ç¼“å†²åŒº: {conversation_id}")

    async def _process_audio_data(self, connection_id: str, audio_data: Dict[str, Any]):
        """å¤„ç†éŸ³é¢‘æ•°æ® - ä½¿ç”¨VADç´¯ç§¯å’ŒTurn Detectionåˆ¤æ–­"""
        try:
            # è·å–éŸ³é¢‘æ•°æ®
            audio_b64 = audio_data.get("audio", "")
            if not audio_b64:
                logger.warning(f"âš ï¸ ç©ºéŸ³é¢‘æ•°æ®: {connection_id}")
                return

            conversation_id = audio_data.get("conversation_id", connection_id)

            # åˆå§‹åŒ–è¯­éŸ³ç¼“å†²åŒº
            if conversation_id not in self.speech_buffers:
                self._reset_speech_buffer(conversation_id)

            buffer_info = self.speech_buffers[conversation_id]

            # è§£ç éŸ³é¢‘æ•°æ®
            try:
                audio_bytes = base64.b64decode(audio_b64)
                # è½¬æ¢ä¸ºnumpyæ•°ç»„ (int16 -> float32)
                audio_array = np.frombuffer(audio_bytes, dtype=np.int16).astype(np.float32) / 32768.0

                logger.debug(f"ğŸ¤ éŸ³é¢‘è§£ç : é•¿åº¦={len(audio_array)}, èŒƒå›´=[{audio_array.min():.3f}, {audio_array.max():.3f}]")

                # VADæ£€æµ‹ - æ£€æŸ¥æ˜¯å¦æœ‰è¯­éŸ³æ´»åŠ¨
                has_speech = await self._vad_detect_speech(audio_array)

                if has_speech:
                    # æ£€æµ‹åˆ°è¯­éŸ³ï¼Œç´¯ç§¯åˆ°ç¼“å†²åŒº
                    buffer_info["buffer"].extend(audio_array.tolist())
                    buffer_info["last_speech_time"] = time.time()
                    buffer_info["silence_count"] = 0

                    if not buffer_info["speech_started"]:
                        buffer_info["speech_started"] = True
                        buffer_info["is_speaking"] = True
                        logger.info(f"ğŸ¤ å¼€å§‹è¯­éŸ³æ®µ: {conversation_id}")

                        # å‘é€è¯­éŸ³å¼€å§‹äº‹ä»¶
                        await self._send_to_connection(connection_id, {
                            "type": "speech_start",
                            "data": {
                                "conversation_id": conversation_id,
                                "timestamp": time.time()
                            }
                        })
                else:
                    # æ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³
                    if buffer_info["speech_started"]:
                        buffer_info["silence_count"] += 1

                        # ä½¿ç”¨é…ç½®çš„é™éŸ³æ£€æµ‹å‚æ•°
                        if buffer_info["silence_count"] >= self.vad_config.silence_duration_frames:
                            await self._finalize_speech_segment(connection_id, conversation_id)

            except Exception as decode_error:
                logger.error(f"âŒ éŸ³é¢‘è§£ç å¤±è´¥: {decode_error}")
                return

        except Exception as e:
            logger.error(f"âŒ éŸ³é¢‘å¤„ç†å¤±è´¥: {e}")

    async def _vad_detect_speech(self, audio_array: np.ndarray) -> bool:
        """VADè¯­éŸ³æ´»åŠ¨æ£€æµ‹ - ä½¿ç”¨é…ç½®åŒ–å‚æ•°"""
        try:
            # ä½¿ç”¨é…ç½®çš„å‚æ•°
            energy = np.sqrt(np.mean(audio_array ** 2))

            # æ·»åŠ éŸ³é¢‘é•¿åº¦æ£€æŸ¥ï¼Œé¿å…å™ªéŸ³è¯¯è§¦å‘
            if len(audio_array) < self.vad_config.min_audio_length:
                return False

            # æ·»åŠ å³°å€¼æ£€æµ‹ï¼Œé¿å…æŒç»­ä½èƒ½é‡å™ªéŸ³
            peak_energy = np.max(np.abs(audio_array))

            # ç»¼åˆåˆ¤æ–­ï¼šèƒ½é‡é˜ˆå€¼ + å³°å€¼æ£€æµ‹
            has_speech = (energy > self.vad_config.energy_threshold) and (peak_energy > self.vad_config.peak_threshold)

            if has_speech:
                logger.debug(f"ğŸ¤ VADæ£€æµ‹åˆ°è¯­éŸ³: èƒ½é‡={energy:.6f}, å³°å€¼={peak_energy:.6f}")

            return has_speech

        except Exception as e:
            logger.error(f"âŒ VADæ£€æµ‹å¤±è´¥: {e}")
            return False

    async def _finalize_speech_segment(self, connection_id: str, conversation_id: str):
        """å®Œæˆè¯­éŸ³æ®µå¤„ç†"""
        try:
            if conversation_id not in self.speech_buffers:
                return

            buffer_info = self.speech_buffers[conversation_id]

            # é˜²æ­¢é‡å¤å¤„ç†
            if not buffer_info["speech_started"]:
                return

            # å›éŸ³æŠ‘åˆ¶ï¼šæ£€æŸ¥AIæ˜¯å¦æ­£åœ¨è¯´è¯æˆ–åˆšè¯´å®Œè¯
            if self._is_ai_speaking_or_recently_spoke(connection_id):
                logger.info(f"ğŸ”‡ å›éŸ³æŠ‘åˆ¶ï¼šAIæ­£åœ¨è¯´è¯æˆ–åˆšè¯´å®Œè¯ï¼Œå¿½ç•¥ç”¨æˆ·è¯­éŸ³: {conversation_id}")
                # é‡ç½®çŠ¶æ€ä½†ä¸æ¸…ç©ºbufferï¼Œç»§ç»­ç›‘å¬
                buffer_info["speech_started"] = False
                buffer_info["silence_count"] = 0
                buffer_info["buffer"].clear()  # æ¸…ç©ºç¼“å†²åŒºé¿å…ç´¯ç§¯
                return

            # ä½¿ç”¨é…ç½®çš„æœ€å°éŸ³é¢‘é•¿åº¦æ£€æµ‹
            min_audio_samples = self.vad_config.min_speech_frames * 1000  # è½¬æ¢ä¸ºæ ·æœ¬æ•° (16kHz)
            if len(buffer_info["buffer"]) < min_audio_samples:
                logger.info(f"ğŸ¤ è¯­éŸ³æ®µå¤ªçŸ­ï¼Œå¿½ç•¥: {conversation_id} (é•¿åº¦: {len(buffer_info['buffer'])}, éœ€è¦: {min_audio_samples})")
                # é‡ç½®çŠ¶æ€ä½†ä¸æ¸…ç©ºbufferï¼Œç»§ç»­ç›‘å¬
                buffer_info["speech_started"] = False
                buffer_info["silence_count"] = 0
                return

            logger.info(f"ğŸ¤ å®Œæˆè¯­éŸ³æ®µï¼Œå¼€å§‹è½¬å½•: {conversation_id} (éŸ³é¢‘é•¿åº¦: {len(buffer_info['buffer'])})")

            # æ ‡è®°ä¸ºæ­£åœ¨å¤„ç†
            buffer_info["speech_started"] = False
            buffer_info["is_speaking"] = False

            # å‘é€è¯­éŸ³ç»“æŸäº‹ä»¶
            await self._send_to_connection(connection_id, {
                "type": "speech_end",
                "data": {
                    "conversation_id": conversation_id,
                    "timestamp": time.time()
                }
            })

            # å®Œæ•´è½¬å½•
            audio_array = np.array(buffer_info["buffer"], dtype=np.float32)
            transcript = await self._transcribe_with_whisper(audio_array)

            logger.info(f"ğŸ¤ è½¬å½•ç»“æœ: '{transcript}'")

            # å‘é€è½¬å½•ç»“æœ
            await self._send_to_connection(connection_id, {
                "type": "transcription_result",
                "data": {
                    "text": transcript,
                    "confidence": 0.9,
                    "is_final": True,
                    "conversation_id": conversation_id
                }
            })

            # ä½¿ç”¨Turn Detectionåˆ¤æ–­æ˜¯å¦åº”è¯¥å›å¤
            if transcript.strip():
                should_respond = await self._check_turn_completion(transcript, conversation_id)

                if should_respond:
                    # è·å–LLMå“åº”
                    response = await self._get_llm_response(transcript)

                    # å‘é€LLMå“åº”
                    await self._send_to_connection(connection_id, {
                        "type": "llm_response",
                        "data": {
                            "text": response,
                            "conversation_id": conversation_id,
                            "timestamp": time.time()
                        }
                    })

                    # ä½¿ç”¨Spark-TTSæ’­æ”¾
                    await self._speak_with_spark_tts(connection_id, response, conversation_id)
                else:
                    logger.info("ğŸ¤ Turn Detection: ç”¨æˆ·è¿˜æƒ³ç»§ç»­è¯´è¯ï¼Œä¿æŒç›‘å¬")

            # æ¸…ç©ºç¼“å†²åŒºï¼Œå‡†å¤‡ä¸‹ä¸€æ®µè¯­éŸ³
            buffer_info["buffer"] = []

        except Exception as e:
            logger.error(f"âŒ è¯­éŸ³æ®µå¤„ç†å¤±è´¥: {e}")

    async def _check_turn_completion(self, transcript: str, conversation_id: str) -> bool:
        """ä½¿ç”¨Turn Detectionæ£€æŸ¥è½®æ¬¡æ˜¯å¦å®Œæˆ"""
        try:
            # ç®€åŒ–çš„Turn Detectioné€»è¾‘
            # åœ¨çœŸå®å®ç°ä¸­ï¼Œè¿™é‡Œåº”è¯¥è°ƒç”¨TEN Turn Detection

            # ç®€å•è§„åˆ™ï¼šå¦‚æœå¥å­ä»¥å¥å·ã€é—®å·ã€æ„Ÿå¹å·ç»“å°¾ï¼Œè®¤ä¸ºå®Œæˆ
            if transcript.strip().endswith(('ã€‚', 'ï¼Ÿ', 'ï¼', '.', '?', '!')):
                logger.info("ğŸ¯ Turn Detection: æ£€æµ‹åˆ°å¥å­ç»“æŸï¼Œåº”è¯¥å›å¤")
                return True

            # å¦‚æœå¥å­è¾ƒçŸ­ä¸”å®Œæ•´ï¼Œä¹Ÿè®¤ä¸ºå®Œæˆ
            if len(transcript.strip()) > 3 and len(transcript.strip()) < 50:
                logger.info("ğŸ¯ Turn Detection: çŸ­å¥å®Œæ•´ï¼Œåº”è¯¥å›å¤")
                return True

            logger.info("ğŸ¯ Turn Detection: ç”¨æˆ·å¯èƒ½è¿˜æƒ³ç»§ç»­è¯´è¯")
            return False

        except Exception as e:
            logger.error(f"âŒ Turn Detectionå¤±è´¥: {e}")
            # é™çº§å¤„ç†ï¼šé»˜è®¤è®¤ä¸ºå®Œæˆ
            return True

    async def _speak_with_spark_tts(self, connection_id: str, text: str, conversation_id: str):
        """ä½¿ç”¨Spark-TTSæ’­æ”¾æ–‡æœ¬"""
        try:
            # è®°å½•AIå¼€å§‹è¯´è¯æ—¶é—´ï¼ˆå›éŸ³æŠ‘åˆ¶ï¼‰
            current_time = time.time()
            self.ai_speaking_periods[connection_id] = {
                "start_time": current_time,
                "end_time": None
            }

            # å‘é€TTSå¼€å§‹äº‹ä»¶
            await self._send_to_connection(connection_id, {
                "type": "tts_start",
                "data": {
                    "text": text,
                    "conversation_id": conversation_id,
                    "timestamp": current_time
                }
            })

            if self.spark_tts and self.spark_tts.is_model_loaded():
                # ä½¿ç”¨Spark-TTSæµå¼åˆæˆ
                logger.info(f"âš¡ å¼€å§‹Spark-TTSæ’­æ”¾: {text}")
                chunk_count = 0

                # ç”ŸæˆéŸ³é¢‘æµ - ä½¿ç”¨æ ‡å‡†è¯­é€Ÿï¼ˆSpark-TTSæ”¯æŒçš„é€Ÿåº¦å€¼ï¼‰
                for audio_chunk in self.spark_tts.synthesize_stream(text, speed=1.0):
                    chunk_count += 1

                    # æå–éŸ³é¢‘æ•°æ®
                    audio_array = audio_chunk.get("audio", np.array([]))
                    sample_rate = audio_chunk.get("sample_rate", 22050)

                    if len(audio_array) == 0:
                        continue

                    # è½¬æ¢ä¸ºint16æ ¼å¼çš„WAVå­—èŠ‚æ•°æ®
                    audio_int16 = (audio_array * 32767).astype(np.int16)
                    wav_bytes = audio_int16.tobytes()

                    # éŸ³é¢‘å—å»é‡æ£€æŸ¥
                    import hashlib
                    audio_hash = hashlib.md5(wav_bytes).hexdigest()

                    if connection_id not in self.sent_audio_hashes:
                        self.sent_audio_hashes[connection_id] = set()

                    if audio_hash in self.sent_audio_hashes[connection_id]:
                        logger.debug(f"ğŸ”„ è·³è¿‡é‡å¤éŸ³é¢‘å—: {chunk_count}")
                        continue

                    self.sent_audio_hashes[connection_id].add(audio_hash)

                    # å°†éŸ³é¢‘æ•°æ®ç¼–ç ä¸ºbase64
                    audio_b64 = base64.b64encode(wav_bytes).decode('utf-8')

                    # å‘é€éŸ³é¢‘å—
                    success = await self._send_to_connection(connection_id, {
                        "type": "audio_chunk",
                        "data": {
                            "audio": audio_b64,
                            "chunk_id": chunk_count,
                            "sample_rate": sample_rate,
                            "conversation_id": conversation_id,
                            "timestamp": time.time()
                        }
                    })

                    if not success:
                        logger.warning(f"âš ï¸ å‘é€éŸ³é¢‘å—å¤±è´¥ï¼Œåœæ­¢TTSæ’­æ”¾: {chunk_count}")
                        break

                    logger.debug(f"ğŸµ å‘é€éŸ³é¢‘å— {chunk_count}: {len(wav_bytes)} å­—èŠ‚")

                    # æ·»åŠ å°å»¶è¿Ÿï¼Œé˜²æ­¢éŸ³é¢‘å—å‘é€è¿‡å¿«
                    import asyncio
                    await asyncio.sleep(0.05)  # 50mså»¶è¿Ÿ

                logger.info(f"âœ… Fish Audio TTSæ’­æ”¾å®Œæˆï¼Œå…±{chunk_count}ä¸ªéŸ³é¢‘å—")

            else:
                # é™çº§åˆ°æ¨¡æ‹ŸTTS
                logger.warning("âš ï¸ Fish Audio TTSä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹ŸTTS")
                import asyncio
                await asyncio.sleep(len(text) * 0.1)  # æ¨¡æ‹Ÿæ’­æ”¾æ—¶é—´

            # æ— è®ºå¦‚ä½•éƒ½è¦å°è¯•æ¢å¤åˆ°ç›‘å¬çŠ¶æ€
            try:
                # è®°å½•AIè¯´è¯ç»“æŸæ—¶é—´ï¼ˆå›éŸ³æŠ‘åˆ¶ï¼‰
                current_time = time.time()
                if connection_id in self.ai_speaking_periods:
                    self.ai_speaking_periods[connection_id]["end_time"] = current_time

                # å‘é€TTSç»“æŸäº‹ä»¶
                if connection_id in self.active_connections:
                    await self._send_to_connection(connection_id, {
                        "type": "tts_end",
                        "data": {
                            "text": text,
                            "conversation_id": conversation_id,
                            "timestamp": current_time
                        }
                    })

                # ç¡®ä¿æ¢å¤åˆ°ç›‘å¬çŠ¶æ€
                await self._ensure_listening_state(connection_id)

            except Exception as e:
                logger.warning(f"âš ï¸ TTSå®Œæˆåå¤„ç†å¼‚å¸¸: {e}")
                # å³ä½¿å‘ç”Ÿå¼‚å¸¸ï¼Œä¹Ÿè¦å°è¯•æ¢å¤ç›‘å¬çŠ¶æ€
                try:
                    await self._ensure_listening_state(connection_id)
                except:
                    logger.error(f"âŒ æ— æ³•æ¢å¤ç›‘å¬çŠ¶æ€: {connection_id}")

        except Exception as e:
            logger.error(f"âŒ Fish Audio TTSæ’­æ”¾å¤±è´¥: {e}")

            # å‘é€TTSé”™è¯¯äº‹ä»¶
            await self._send_to_connection(connection_id, {
                "type": "tts_error",
                "data": {
                    "text": text,
                    "error": str(e),
                    "conversation_id": conversation_id,
                    "timestamp": time.time()
                }
            })

    async def _transcribe_with_whisper(self, audio_array: np.ndarray) -> str:
        """ä½¿ç”¨Whisperè¿›è¡Œè¯­éŸ³è½¬å½•"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰Whisperæ¨¡å‹
            if not hasattr(self, 'whisper_model') or self.whisper_model is None:
                # åˆå§‹åŒ–Whisperæ¨¡å‹ - ä½¿ç”¨é…ç½®åŒ–å‚æ•°
                try:
                    from faster_whisper import WhisperModel
                    logger.info("ğŸ¯ åˆå§‹åŒ–Whisperæ¨¡å‹...")
                    # ä½¿ç”¨é…ç½®çš„å‚æ•°
                    self.whisper_model = WhisperModel(
                        self.whisper_config.model_size,
                        device=self.whisper_config.device,
                        compute_type=self.whisper_config.compute_type,
                        num_workers=1,  # å•çº¿ç¨‹é¿å…èµ„æºç«äº‰
                        download_root="models/whisper"  # æœ¬åœ°æ¨¡å‹ç›®å½•
                    )
                    logger.info("âœ… Whisperæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
                except ImportError:
                    logger.error("âŒ faster-whisperæœªå®‰è£…")
                    return "è¯­éŸ³è¯†åˆ«ä¸å¯ç”¨"
                except Exception as e:
                    logger.error(f"âŒ Whisperæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
                    return "è¯­éŸ³è¯†åˆ«åˆå§‹åŒ–å¤±è´¥"

            # æ£€æŸ¥éŸ³é¢‘æ•°æ®
            if len(audio_array) < 1600:  # è‡³å°‘0.1ç§’çš„éŸ³é¢‘
                logger.warning(f"âš ï¸ éŸ³é¢‘æ•°æ®å¤ªçŸ­: {len(audio_array)} æ ·æœ¬")
                return ""

            # æ£€æŸ¥éŸ³é¢‘èƒ½é‡
            audio_energy = np.sqrt(np.mean(audio_array ** 2))
            logger.debug(f"ğŸ¤ éŸ³é¢‘èƒ½é‡: {audio_energy:.6f}")
            if audio_energy < 0.001:
                logger.warning(f"âš ï¸ éŸ³é¢‘èƒ½é‡å¤ªä½: {audio_energy:.6f}")
                return ""

            # åˆ›å»ºä¸´æ—¶WAVæ–‡ä»¶
            import tempfile
            import wave

            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
                # å†™å…¥WAVæ–‡ä»¶
                with wave.open(temp_file.name, 'wb') as wav_file:
                    wav_file.setnchannels(1)  # å•å£°é“
                    wav_file.setsampwidth(2)  # 16ä½
                    wav_file.setframerate(16000)  # 16kHz
                    # è½¬æ¢ä¸ºint16
                    audio_int16 = (audio_array * 32767).astype(np.int16)
                    wav_file.writeframes(audio_int16.tobytes())

                logger.debug(f"ğŸ¤ å¼€å§‹Whisperè½¬å½•ï¼Œæ–‡ä»¶: {temp_file.name}")

                # ä½¿ç”¨Whisper large-v3-turboè½¬å½• - ä¸“é—¨ä¼˜åŒ–ä¸­æ–‡è¯†åˆ«
                segments, _ = self.whisper_model.transcribe(
                    temp_file.name,
                    language="zh",  # ä¸­æ–‡
                    beam_size=self.whisper_config.beam_size,
                    initial_prompt="ä»¥ä¸‹æ˜¯æ™®é€šè¯çš„å¥å­ï¼ŒåŒ…å«æ—¥å¸¸å¯¹è¯å†…å®¹ã€‚",  # ä¼˜åŒ–ä¸­æ–‡æç¤º
                    vad_filter=False,  # ç¦ç”¨å†…ç½®VADï¼Œä½¿ç”¨æˆ‘ä»¬è‡ªå·±çš„VAD
                    word_timestamps=False,  # ç¦ç”¨è¯çº§æ—¶é—´æˆ³æé«˜é€Ÿåº¦
                    condition_on_previous_text=False,  # ç¦ç”¨ä¸Šä¸‹æ–‡ä¾èµ–æé«˜å‡†ç¡®æ€§
                    temperature=self.whisper_config.temperature,
                    compression_ratio_threshold=self.whisper_config.compression_ratio_threshold,
                    log_prob_threshold=self.whisper_config.log_prob_threshold,
                    no_speech_threshold=self.whisper_config.no_speech_threshold,
                    # large-v3-turboä¸“ç”¨ä¼˜åŒ–å‚æ•°
                    repetition_penalty=1.1,  # é‡å¤æƒ©ç½šï¼Œé¿å…é‡å¤è¯†åˆ«
                    length_penalty=1.0,      # é•¿åº¦æƒ©ç½š
                    patience=1               # è€å¿ƒå‚æ•°ï¼Œæé«˜å‡†ç¡®æ€§
                )

                # æå–è½¬å½•æ–‡æœ¬
                transcript = ""
                for segment in segments:
                    logger.debug(f"ğŸ¤ Whisperç‰‡æ®µ: '{segment.text}'")
                    transcript += segment.text

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                import os
                os.unlink(temp_file.name)

                return transcript.strip()

        except Exception as e:
            logger.error(f"âŒ Whisperè½¬å½•å¤±è´¥: {e}")
            return "è½¬å½•å¤±è´¥"

# å…¨å±€æœåŠ¡å™¨å®ä¾‹
voice_server = SimpleVoiceServer()

@voice_server.app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨äº‹ä»¶"""
    logger.info("ğŸš€ åˆå§‹åŒ–ç®€åŒ–è¯­éŸ³äº¤äº’æœåŠ¡å™¨...")

    # åˆå§‹åŒ–Spark-TTSå¼•æ“
    await voice_server.initialize_spark_tts()
    logger.info("âœ… Spark-TTSå¼•æ“åˆå§‹åŒ–æˆåŠŸ")

    logger.info("âœ… ç®€åŒ–è¯­éŸ³äº¤äº’æœåŠ¡å™¨å¯åŠ¨å®Œæˆ")

@voice_server.app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­äº‹ä»¶"""
    logger.info("ğŸ›‘ ç®€åŒ–è¯­éŸ³äº¤äº’æœåŠ¡å™¨å…³é—­")

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¯åŠ¨ç®€åŒ–è¯­éŸ³äº¤äº’æœåŠ¡å™¨...")
    
    uvicorn.run(
        "simple_voice_server:voice_server.app",
        host="0.0.0.0",
        port=8002,  # ä½¿ç”¨æ–°ç«¯å£
        reload=False,
        log_level="info"
    )

if __name__ == "__main__":
    main()
